{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding a Large Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to walk through how to encode a large knowledge graph for the purposes of Graph RAG. We will provide two examples of how to do so, along with demonstration code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Building from Already Existing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most RAG scenarios, the subset of the information corpus that gets retrieved is crucial for whether the appropriate response to the LLM. The same is true for GNN based RAG. Consider the following dataset WebQSP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import WebQSPDataset, UpdatedWebQSPDataset\n",
    "\n",
    "# Computationally expensive, so running a small sample for now to show off the schema\n",
    "# ds = WebQSPDataset('dataset')\n",
    "num_questions = 100\n",
    "ds = UpdatedWebQSPDataset('small_sample', limit=num_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WebQSP is a dataset that is based off of a subset of the Freebase Knowledge Graph, which is an open-source knowledge graph formerly maintained by Google. For each question-answer pair in the dataset, a subgraph was chosen based on a Semantic SPARQL search on the larger knowledge graph, to provide relevent context on finding the answer. So each entry in the dataset consists of:\n",
    "- A question to be answered\n",
    "- The answer\n",
    "- A knowledge graph subgraph of Freebase that has the context needed to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.raw_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this dataset can be trained on as-is, a couple problems emerge from doing so:\n",
    "1. A retrieval algorithm needs to be implemented and executed during inference time, that might not appropriately correspond to the algorithm that was used to generate the dataset subgraphs.\n",
    "2. The dataset as is not stored computationally efficiently, as there will exist many duplicate nodes and edges that are shared between the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, it makes sense in this scenario to be able to encode all the entries into a large knowledge graph, so that duplicate nodes and edges can be avoided, and so that alternative retrieval algorithms can be tried. We can do this with the LargeGraphIndexer class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import LargeGraphIndexer, Data, get_features_for_triplets_groups\n",
    "from torch_geometric.nn.nlp import SentenceTransformer\n",
    "import time\n",
    "import torch\n",
    "import tqdm\n",
    "from itertools import chain\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset_graphs = [[tuple(trip) for trip in graph] for graph in ds.raw_dataset['graph']]\n",
    "print(raw_dataset_graphs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the benefits of this indexer in action, we will use the following model to encode this sample of graphs using LargeGraphIndexer, along with naively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer(model_name='sentence-transformers/all-roberta-large-v1').to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compare the clock times of encoding using both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing question-by-question\n",
    "dataset_graphs_embedded = []\n",
    "start = time.time()\n",
    "for graph in tqdm.tqdm(raw_dataset_graphs):\n",
    "    nodes_map = dict()\n",
    "    edges_map = dict()\n",
    "    edge_idx_base = []\n",
    "\n",
    "    for src, edge, dst in graph:\n",
    "        # Collect nodes\n",
    "        if src not in nodes_map:\n",
    "            nodes_map[src] = len(nodes_map)\n",
    "        if dst not in nodes_map:\n",
    "            nodes_map[dst] = len(nodes_map)\n",
    "        \n",
    "        # Collect edge types\n",
    "        if edge not in edges_map:\n",
    "            edges_map[edge] = len(edges_map)\n",
    "\n",
    "        # Record edge\n",
    "        edge_idx_base.append((nodes_map[src], edges_map[edge], nodes_map[dst]))\n",
    "    \n",
    "    # Encode nodes and edges\n",
    "    sorted_nodes = list(sorted(nodes_map.keys(), key=lambda x: nodes_map[x]))\n",
    "    sorted_edges = list(sorted(edges_map.keys(), key=lambda x: edges_map[x]))\n",
    "\n",
    "    x = model.encode(sorted_nodes, batch_size=256)\n",
    "    edge_attrs_map = model.encode(sorted_edges, batch_size=256)\n",
    "    \n",
    "    edge_attrs = []\n",
    "    edge_idx = []\n",
    "    for trip in edge_idx_base:\n",
    "        edge_attrs.append(edge_attrs_map[trip[1]])\n",
    "        edge_idx.append([trip[0], trip[2]])\n",
    "\n",
    "    dataset_graphs_embedded.append(Data(x=x, edge_index=torch.tensor(edge_idx).T, edge_attr=torch.stack(edge_attrs, dim=0)))\n",
    "    \n",
    "    \n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LargeGraphIndexer to make one large knowledge graph\n",
    "from torch_geometric.data.large_graph_indexer import EDGE_RELATION\n",
    "\n",
    "start = time.time()\n",
    "all_triplets_together = chain.from_iterable(raw_dataset_graphs)\n",
    "# Index as one large graph\n",
    "print('Indexing...')\n",
    "indexer = LargeGraphIndexer.from_triplets(all_triplets_together)\n",
    "\n",
    "# first the nodes\n",
    "unique_nodes = indexer.get_unique_node_features()\n",
    "node_encs = model.encode(unique_nodes, batch_size=256)\n",
    "indexer.add_node_feature(new_feature_name='x', new_feature_vals=node_encs)\n",
    "\n",
    "# then the edges\n",
    "unique_edges = indexer.get_unique_edge_features(feature_name=EDGE_RELATION)\n",
    "edge_attr = model.encode(unique_edges, batch_size=256)\n",
    "indexer.add_edge_feature(new_feature_name=\"edge_attr\", new_feature_vals=edge_attr, map_from_feature=EDGE_RELATION)\n",
    "\n",
    "ckpt_time = time.time()\n",
    "whole_knowledge_graph = indexer.to_data(node_feature_name='x', edge_feature_name='edge_attr') \n",
    "whole_graph_done = time.time()\n",
    "print(f\"Time to create whole knowledge_graph: {whole_graph_done-start}\")\n",
    "\n",
    "# Compute this to make sure we're comparing like to like on final time printout\n",
    "whole_graph_diff = whole_graph_done-ckpt_time\n",
    "\n",
    "# retrieve subgraphs\n",
    "print('Retrieving Subgraphs...')\n",
    "dataset_graphs_embedded_largegraphindexer = [graph for graph in tqdm.tqdm(get_features_for_triplets_groups(indexer=indexer, triplet_groups=raw_dataset_graphs), total=num_questions)]\n",
    "print(time.time()-start-whole_graph_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large graph indexer allows us to compute the entire knowledge graph from a series of samples, so that new retrieval methods can also be tested on the entire graph. We will see this attempted in practice later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that, although the times are relatively similar right now, the speedup with largegraphindexer will be much higher as the size of the knowledge graph grows. This is due to the speedup being a factor of the number of unique nodes and edges in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_graphs_embedded_largegraphindexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_graphs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the two results to be functionally identical, with the differences being due to floating point jitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_are_close_enough(ground_truth: Data, new_method: Data, thresh=.8):\n",
    "    def _sorted_tensors_are_close(tensor1, tensor2):\n",
    "        return torch.all(torch.isclose(tensor1.sort(dim=0)[0], tensor2.sort(dim=0)[0]).float().mean(axis=1) > thresh)\n",
    "    def _graphs_are_same(tensor1, tensor2):\n",
    "        return nx.weisfeiler_lehman_graph_hash(nx.Graph(tensor1.T)) == nx.weisfeiler_lehman_graph_hash(nx.Graph(tensor2.T))\n",
    "    return _sorted_tensors_are_close(ground_truth.x, new_method.x) \\\n",
    "        and _sorted_tensors_are_close(ground_truth.edge_attr, new_method.edge_attr) \\\n",
    "        and _graphs_are_same(ground_truth.edge_index, new_method.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_match = True\n",
    "for old_graph, new_graph in tqdm.tqdm(zip(dataset_graphs_embedded, dataset_graphs_embedded_largegraphindexer), total=num_questions):\n",
    "    all_results_match &= results_are_close_enough(old_graph, new_graph)\n",
    "all_results_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scaled up to the entire dataset, we see a 2x speedup with indexing this way.\n",
    "\n",
    "WebQSPDataset is a question-by-question implementation.\n",
    "\n",
    "UpdatedQSPDataset is a LargeGraphIndexer implementation.\n",
    "\n",
    "These were computed on an RTX 4090 with 24GB of memory. Your milage may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_number_of_graphs = 4700 # out of 4700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: WebQSP doesn't let you limit the number of questions, so we compute the whole dataset and estimate the time by assuming each question takes the same amount of time\n",
    "start = time.time()\n",
    "ds_basic = WebQSPDataset('basic_dataset')\n",
    "web_qsp_time = (time.time() - start)*demo_number_of_graphs/4700\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ds_updated = UpdatedWebQSPDataset('updated_dataset', limit=demo_number_of_graphs)\n",
    "updated_time = time.time() - start\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(['WebQSP', 'UpdatedQSP'], [web_qsp_time,, updated_time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Building a new Dataset from Questions and an already-existing Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will take a set of multi-hop questions, and combine them with an existing Wikidata knowledge graph to produce a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be continued in 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg-local-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
