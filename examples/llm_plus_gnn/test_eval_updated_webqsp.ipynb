{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaristei/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from updated_qsp_dataset import UpdatedWebQSPDataset\n",
    "from raw_qsp_dataset import RawWebQSPDataset\n",
    "from unittest.mock import patch\n",
    "from torch_geometric.data import Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_call_iter():\n",
    "    a, batch_size = [], 256\n",
    "    i = 0\n",
    "    while True:\n",
    "        rv = torch.Tensor([list(range(i, i+len(a)))]).T\n",
    "        i += len(a)\n",
    "        a = yield rv\n",
    "        if a is None:\n",
    "            a = []\n",
    "gen = tokenizer_call_iter()\n",
    "next(gen)\n",
    "def tokenizer_call(a, batch_size):\n",
    "    return gen.send(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding questions...\n",
      "Encoding graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 46.95it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "old_token_mock, old_ret_mock = None, None\n",
    "with (patch(\"torch_geometric.datasets.web_qsp_dataset.SentenceTransformer.encode\") as model_mock,\n",
    "      patch(\"raw_qsp_dataset.retrieval_via_pcst\") as pcst_mock):\n",
    "    model_mock.side_effect =tokenizer_call\n",
    "    pcst_mock.return_value = Data(), \"\"\n",
    "    old_dataset = RawWebQSPDataset(root='old_dataset', force_reload=True, limit=2, with_process=True, with_pcst=True)\n",
    "    old_token_mock = model_mock\n",
    "    old_ret_mock = pcst_mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference list for all tokenizer call unique values\n",
    "TOKEN_CALLS = set()\n",
    "for call in model_mock.call_args_list:\n",
    "    text_lst = call[0][0]\n",
    "    TOKEN_CALLS |= set(text_lst)\n",
    "TOKEN_CALLS_MAP = list(TOKEN_CALLS)\n",
    "TOKEN_CALLS_REVERSE_MAP = {v: i for i, v in enumerate(TOKEN_CALLS_MAP)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_from_map_iter():\n",
    "    a = []\n",
    "    while True:\n",
    "        rv = torch.Tensor([TOKEN_CALLS_REVERSE_MAP[t] for t in a])\n",
    "        a = yield rv\n",
    "        if a is None:\n",
    "            a = []\n",
    "gen = tokenizer_from_map_iter()\n",
    "next(gen)\n",
    "def tokenizer_from_map(a, batch_size):\n",
    "    return gen.send(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding questions...\n",
      "Encoding graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 45.33it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "old_token_mock, old_ret_mock = None, None\n",
    "with (patch(\"torch_geometric.datasets.web_qsp_dataset.SentenceTransformer.encode\") as model_mock,\n",
    "      patch(\"raw_qsp_dataset.retrieval_via_pcst\") as pcst_mock):\n",
    "    model_mock.side_effect =tokenizer_from_map\n",
    "    pcst_mock.return_value = Data(), \"\"\n",
    "    old_dataset = RawWebQSPDataset(root='old_dataset', force_reload=True, limit=2, with_process=True, with_pcst=True)\n",
    "    old_token_mock = model_mock\n",
    "    old_ret_mock = pcst_mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding graph...\n",
      "Encoding questions...\n",
      "Retrieving subgraphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.98it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "new_token_mock, new_ret_mock = None, None\n",
    "with (patch(\"torch_geometric.datasets.web_qsp_dataset.SentenceTransformer.encode\") as model_mock,\n",
    "      patch(\"updated_qsp_dataset.retrieval_via_pcst\") as pcst_mock):\n",
    "    model_mock.side_effect = tokenizer_from_map\n",
    "    pcst_mock.return_value = Data(), \"\"\n",
    "    old_dataset = UpdatedWebQSPDataset(root='old_dataset', force_reload=True, limit=2, whole_graph_retrieval=False)\n",
    "    new_token_mock = model_mock\n",
    "    new_ret_mock = pcst_mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_nodes_called = [old_ret_mock.call_args_list[i][0][0].x.int().numpy() for i in range(len(old_ret_mock.call_args_list))]\n",
    "old_edges_called = [old_ret_mock.call_args_list[i][0][0].edge_attr.int().numpy() for i in range(len(old_ret_mock.call_args_list))]\n",
    "old_question_called = [old_ret_mock.call_args_list[i][0][1].int().numpy() for i in range(len(old_ret_mock.call_args_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nodes_called = [new_ret_mock.call_args_list[i][0][0].x.int().numpy() for i in range(len(new_ret_mock.call_args_list))]\n",
    "new_edges_called = [new_ret_mock.call_args_list[i][0][0].edge_attr.int().numpy() for i in range(len(new_ret_mock.call_args_list))]\n",
    "new_question_called = [new_ret_mock.call_args_list[i][0][1].int().numpy() for i in range(len(new_ret_mock.call_args_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(old_ret_mock.call_args_list)):\n",
    "    print(set(old_nodes_called[i]) == set(new_nodes_called[i]))\n",
    "    print(set(old_edges_called[i]) == set(new_edges_called[i]))\n",
    "    print(old_question_called[i] == new_question_called[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(3073, dtype=int32), array(2115, dtype=int32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_question_called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([   0., 3971., 3972.,  ..., 8044., 8046., 5478.]),\n",
       " tensor([  12., 3985., 3987.,  ..., 3953., 8035., 8038.])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_nodes_called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = UpdatedWebQSPDataset(root='updated_dataset',force_reload=True, limit=2, whole_graph_retrieval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[12, 1024], edge_index=[2, 12], edge_attr=[12, 1024], question='Question: what is the name of justin bieber brother\n",
       "Answer: ', label='jaxon bieber', desc='node_id,node_attr\n",
       "15,justin bieber\n",
       "151,pattie mallette\n",
       "286,english language\n",
       "294,jaxon bieber\n",
       "346,yves bole\n",
       "356,jeremy bieber\n",
       "452,jazmyn bieber\n",
       "545,m.0wfn4pm\n",
       "551,m.0gxnnwp\n",
       "933,m.0gxnnwc\n",
       "1032,this is justin bieber\n",
       "1359,m.0129jzth\n",
       "\n",
       "src,edge_attr,dst\n",
       "346,people.person.languages,286\n",
       "1032,film.film.language,286\n",
       "346,influence.influence_node.influenced_by,15\n",
       "151,people.person.children,15\n",
       "294,people.person.parents,356\n",
       "545,people.sibling_relationship.sibling,151\n",
       "933,people.sibling_relationship.sibling,452\n",
       "1359,people.sibling_relationship.sibling,346\n",
       "551,people.sibling_relationship.sibling,294\n",
       "15,people.person.sibling_s,933\n",
       "933,people.sibling_relationship.sibling,15\n",
       "551,people.sibling_relationship.sibling,15\n",
       "', num_nodes=12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[15, 1024], edge_index=[2, 20], edge_attr=[20, 1024], question='Question: what is the name of justin bieber brother\n",
       "Answer: ', label='jaxon bieber', desc='index,node_id,node_attr\n",
       "54,54,m.0gxnp5m\n",
       "307,307,m.0129jzth\n",
       "391,391,pattie mallette\n",
       "650,650,english language\n",
       "837,837,justin bieber\n",
       "934,934,this is justin bieber\n",
       "1022,1022,m.0gxnp5x\n",
       "1123,1123,jeremy bieber\n",
       "1149,1149,m.0gxnnwp\n",
       "1847,1847,m.0gxnnwc\n",
       "2294,2294,yves bole\n",
       "2702,2702,m.0gxnp5d\n",
       "2719,2719,jazmyn bieber\n",
       "2880,2880,m.0wfn4pm\n",
       "2882,2882,jaxon bieber\n",
       "\n",
       "src,edge_attr,dst\n",
       "2294,people.person.languages,650\n",
       "934,film.film.language,650\n",
       "2294,influence.influence_node.influenced_by,837\n",
       "391,people.person.children,837\n",
       "2882,people.person.parents,1123\n",
       "2880,people.sibling_relationship.sibling,391\n",
       "2882,people.person.sibling_s,1149\n",
       "837,base.popstra.celebrity.hangout,1022\n",
       "1847,people.sibling_relationship.sibling,2719\n",
       "307,people.sibling_relationship.sibling,2294\n",
       "391,people.person.sibling_s,2880\n",
       "1149,people.sibling_relationship.sibling,2882\n",
       "2294,people.person.sibling_s,307\n",
       "837,people.person.sibling_s,1847\n",
       "837,base.popstra.celebrity.hangout,2702\n",
       "2719,people.person.sibling_s,1847\n",
       "1847,people.sibling_relationship.sibling,837\n",
       "837,people.person.sibling_s,1149\n",
       "837,base.popstra.celebrity.hangout,54\n",
       "1149,people.sibling_relationship.sibling,837\n",
       "', num_nodes=15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1709, 1024], edge_index=[2, 9088], edge_attr=[9088, 1024], num_nodes=1709)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_dataset.raw_graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1709, 1024], edge_index=[2, 9088], edge_attr=[9088, 1024], num_nodes=1709, pid=[1709], e_pid=[9088], node_idx=[1709], edge_idx=[9088])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.raw_graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_are_close_enough(ground_truth: Data, new_method: Data, thresh=.9):\n",
    "    def _sorted_tensors_are_close(tensor1, tensor2):\n",
    "        vals = torch.isclose(tensor1.sort(dim=0)[0], tensor2.sort(dim=0)[0]).float().mean(axis=1)\n",
    "        return torch.all(vals > thresh)\n",
    "    def _graphs_are_same(tensor1, tensor2):\n",
    "        return nx.weisfeiler_lehman_graph_hash(nx.Graph(tensor1.T)) == nx.weisfeiler_lehman_graph_hash(nx.Graph(tensor2.T))\n",
    "    val = _sorted_tensors_are_close(ground_truth.x, new_method.x)\n",
    "    val &= _sorted_tensors_are_close(ground_truth.edge_attr, new_method.edge_attr)\n",
    "    val &= _graphs_are_same(ground_truth.edge_index, new_method.edge_index)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_are_close_enough(old_dataset.raw_graphs[0], new_dataset.raw_graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataset.questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset.questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sort(new_dataset.raw_graphs[0].edge_attr, 0)[0].unique(dim=0).size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sort(old_dataset.raw_graphs[0].edge_attr, 0)[0].unique(dim=0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg-local-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
