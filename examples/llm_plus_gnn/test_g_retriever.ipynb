{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from g_retriever import benchmark_models, get_loss, inference_step\n",
    "from torch_geometric.datasets import UpdatedWebQSPDataset\n",
    "from torch_geometric.nn.models import GRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_channels = 1024\n",
    "num_gnn_layers = 1\n",
    "lr=1e-5\n",
    "epochs=2\n",
    "batch_size=8\n",
    "eval_batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = UpdatedWebQSPDataset('test_script', limit=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"GAT_1\", \"MLP_1\"]\n",
    "model_classes = [GRetriever, GRetriever]\n",
    "model_kwargs = [dict(llm_to_use=\"TinyLlama/TinyLlama-1.1B-Chat-v0.1\", num_llm_params=1, gnn_hidden_channels=hidden_channels, num_gnn_layers=num_gnn_layers, mlp_out_dim=2048)] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 'TinyLlama/TinyLlama-1.1B-Chat-v0.1' with configuration: {'revision': 'main', 'max_memory': {0: '22GiB'}, 'low_cpu_mem_usage': True, 'device_map': 'auto', 'torch_dtype': torch.bfloat16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/nlp/llm.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  self.autocast_context = torch.cuda.amp.autocast(dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model GAT_1 appears to already exist.\n",
      "Would you like to retrain?\n",
      "Setting up 'TinyLlama/TinyLlama-1.1B-Chat-v0.1' with configuration: {'revision': 'main', 'max_memory': {0: '22GiB'}, 'low_cpu_mem_usage': True, 'device_map': 'auto', 'torch_dtype': torch.bfloat16}\n",
      "16 8 8\n",
      "Total Prep Time (prep_time) = 1.87\n",
      "Training beginning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1|2: 100%|██████████| 2/2 [00:00<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1|2,Train Loss (Epoch Mean): 3.2131307125091553\n",
      "Epoch: 1|2, Val Loss: 2.994086265563965\n",
      "Checkpointing best val loss model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2|2: 100%|██████████| 2/2 [00:00<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2|2,Train Loss (Epoch Mean): 2.8135846853256226\n",
      "Epoch: 2|2, Val Loss: 2.8492681980133057\n",
      "Checkpointing best val loss model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:350: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: dilma rousseff\n",
      "Pred: ['[/SRC] [/EDGE] [/SRC] [/EDGE] [/SRC] [/EDGE] [/']\n",
      "Exception: unterminated character set at position 45\n",
      "------------------\n",
      "Label: paris\n",
      "Pred: ['[/QU] [/QC] [/Q] [/QA] [/QB] [/QC] [/QD']\n",
      "Exception: unterminated character set at position 35\n",
      "------------------\n",
      "Label: ice hockey\n",
      "Pred: ['[/SRC] [/EDGE] [/SRC,EDGE] [/EDGE,SRC] [/EDGE,ED']\n",
      "Exception: unterminated character set at position 39\n",
      "------------------\n",
      "Label: chaz bono|elijah blue allman\n",
      "Pred: ['A: You can use the following code:\\nimport pprint\\n\\ndef load_data():\\n    with open(\"data.txt']\n",
      "Exception: missing ), unterminated subpattern at position 80 (line 5, column 14)\n",
      "------------------\n",
      "Hit: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "Test Acc 0.0\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving eval output for downstream demo...\n",
      "Done!\n",
      "E2E time (e2e_time) = 14.79 seconds\n",
      "E2E tme minus Prep Time = 12.919999999999998 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs for GAT_1 have been found.\n",
      "Would you like to redo?\n",
      "Model MLP_1 appears to already exist.\n",
      "Would you like to retrain?\n",
      "Setting up 'TinyLlama/TinyLlama-1.1B-Chat-v0.1' with configuration: {'revision': 'main', 'max_memory': {0: '22GiB'}, 'low_cpu_mem_usage': True, 'device_map': 'auto', 'torch_dtype': torch.bfloat16}\n",
      "16 8 8\n",
      "Total Prep Time (prep_time) = 1.76\n",
      "Training beginning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1|2: 100%|██████████| 2/2 [00:00<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1|2,Train Loss (Epoch Mean): 3.2048009634017944\n",
      "Epoch: 1|2, Val Loss: 3.015418291091919\n",
      "Checkpointing best val loss model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2|2: 100%|██████████| 2/2 [00:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2|2,Train Loss (Epoch Mean): 2.8109872341156006\n",
      "Epoch: 2|2, Val Loss: 2.8776462078094482\n",
      "Checkpointing best val loss model...\n",
      "Final Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: dilma rousseff\n",
      "Pred: ['[/SRC] [/EDGE] [/SRC] [/EDGE] [/SRC] [/EDGE] [/']\n",
      "Exception: unterminated character set at position 45\n",
      "------------------\n",
      "Label: paris\n",
      "Pred: ['[/QUERY] [/S] [/C] [/A] [/P] [/F] [/R] [/L']\n",
      "Exception: unterminated character set at position 39\n",
      "------------------\n",
      "Label: ice hockey\n",
      "Pred: ['[/SRC] [/EDR] [/Q] [/P] [/T] [/E] [/L] [/']\n",
      "Exception: unterminated character set at position 39\n",
      "------------------\n",
      "Hit: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1: 0.0000\n",
      "Test Acc 0.0\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving eval output for downstream demo...\n",
      "Done!\n",
      "E2E time (e2e_time) = 15.26 seconds\n",
      "E2E tme minus Prep Time = 13.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs for MLP_1 have been found.\n",
      "Would you like to redo?\n",
      "Hallucinates for pure_llm:\n",
      "pure_llm\n",
      "True     5\n",
      "skip     2\n",
      "False    1\n",
      "Name: count, dtype: int64\n",
      "Hallucinates for tuned_llm:\n",
      "tuned_llm\n",
      "True     6\n",
      "skip     1\n",
      "False    1\n",
      "Name: count, dtype: int64\n",
      "Hallucinates for GAT_1:\n",
      "GAT_1\n",
      "skip     4\n",
      "True     2\n",
      "False    2\n",
      "Name: count, dtype: int64\n",
      "Hallucinates for MLP_1:\n",
      "MLP_1\n",
      "skip     3\n",
      "True     3\n",
      "False    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "benchmark_models(model_classes, model_names, model_kwargs, ds, lr, epochs, batch_size, eval_batch_size, get_loss, inference_step, skip_LLMs=False, tiny_llama=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
