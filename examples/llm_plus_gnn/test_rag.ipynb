{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaristei/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiling_utils import create_remote_backend_from_triplets\n",
    "from rag_feature_store import SentenceTransformerFeatureStore\n",
    "from rag_graph_store import NeighborSamplingRAGGraphStore\n",
    "from rag_loader import RagQueryLoader\n",
    "from torch_geometric.datasets import UpdatedWebQSPDataset\n",
    "from torch_geometric.nn.nlp import SentenceTransformer\n",
    "from torch_geometric.datasets.updated_web_qsp_dataset import preprocess_triplet\n",
    "from torch_geometric.data import get_features_for_triplets_groups, Data\n",
    "from itertools import chain\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph...\n",
      "Encoding questions...\n",
      "Retrieving subgraphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 59.04it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subgraphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ds = UpdatedWebQSPDataset(\"small_ds\", force_reload=True, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = list(chain.from_iterable((d['graph'] for d in ds.raw_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is the name of justin bieber brother',\n",
       " 'what character did natalie portman play in star wars',\n",
       " 'what country is the grand bahama island in',\n",
       " 'what kind of money to take to bahamas',\n",
       " 'what character did john noble play in lord of the rings',\n",
       " 'who does joakim noah play for',\n",
       " 'where are the nfl redskins from',\n",
       " 'where did saki live',\n",
       " 'who did draco malloy end up marrying',\n",
       " 'which countries border the us']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = ds.raw_dataset['question']\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_graphs = get_features_for_triplets_groups(ds.indexer, (d['graph'] for d in ds.raw_dataset), pre_transform=preprocess_triplet)\n",
    "num_edges = len(ds.indexer._edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, gs = create_remote_backend_from_triplets(triplets=triplets, node_embedding_model=model, node_method_to_call=\"encode\", path=\"backend\", pre_transform=preprocess_triplet, node_method_kwargs={\"batch_size\": 256}, graph_db=NeighborSamplingRAGGraphStore, feature_db=SentenceTransformerFeatureStore).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loader = RagQueryLoader(data=(fs, gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Metrics to be added to Profiler\n",
    "def _eidx_helper(subg: Data, ground_truth: Data):\n",
    "    subg_eidx, gt_eidx = subg.edge_idx, ground_truth.edge_idx\n",
    "    if isinstance(subg_eidx, torch.Tensor):\n",
    "        subg_eidx = subg_eidx.tolist()\n",
    "    if isinstance(gt_eidx, torch.Tensor):\n",
    "        gt_eidx = gt_eidx.tolist()\n",
    "    subg_e = set(subg_eidx)\n",
    "    gt_e = set(gt_eidx)\n",
    "    return subg_e, gt_e\n",
    "def check_retrieval_accuracy(subg: Data, ground_truth: Data, num_edges: int):\n",
    "    subg_e, gt_e = _eidx_helper(subg, ground_truth)\n",
    "    total_e = set(range(num_edges))\n",
    "    tp = len(subg_e & gt_e)\n",
    "    tn = len(total_e-(subg_e | gt_e))\n",
    "    return (tp+tn)/num_edges\n",
    "def check_retrieval_precision(subg: Data, ground_truth: Data):\n",
    "    subg_e, gt_e = _eidx_helper(subg, ground_truth)\n",
    "    return len(subg_e & gt_e) / len(subg_e)\n",
    "def check_retrieval_recall(subg: Data, ground_truth: Data):\n",
    "    subg_e, gt_e = _eidx_helper(subg, ground_truth)\n",
    "    return len(subg_e & gt_e) / len(gt_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 59.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47500327696945865 0.22471144012078118 0.5290677674578603\n",
      "0.6829990824485516 0.10915320606950563 0.2714877039201363\n",
      "0.4894219425874951 0.05582922824302135 0.5027726432532348\n",
      "0.5146939310525626 0.14810335349092907 0.47180385288966725\n",
      "0.48978896316686327 0.038508934072704865 0.5047106325706595\n",
      "0.556979944946913 0.07315452458620272 0.4376581134803036\n",
      "0.4486826582776249 0.1033375226923614 0.5568096313017307\n",
      "0.6349980338183248 0.06187745246000604 0.35482475118996104\n",
      "0.6690260846768908 0.1052010529182173 0.29521141110545085\n",
      "0.5178660374885307 0.16869006042463552 0.47266231748990367\n"
     ]
    }
   ],
   "source": [
    "for subg, gt in zip((query_loader.query(q) for q in questions), ground_truth_graphs):\n",
    "    print(check_retrieval_accuracy(subg, gt, num_edges), check_retrieval_precision(subg, gt), check_retrieval_recall(subg, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg-local-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
