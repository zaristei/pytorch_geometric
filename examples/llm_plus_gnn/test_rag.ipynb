{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zaristei/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from profiling_utils import create_remote_backend_from_triplets\n",
    "from rag_feature_store import SentenceTransformerFeatureStore\n",
    "from rag_graph_store import NeighborSamplingRAGGraphStore\n",
    "from torch_geometric.loader import RAGQueryLoader\n",
    "from torch_geometric.datasets import UpdatedWebQSPDataset\n",
    "from torch_geometric.nn.nlp import SentenceTransformer\n",
    "from torch_geometric.datasets.updated_web_qsp_dataset import preprocess_triplet, retrieval_via_pcst\n",
    "from torch_geometric.data import get_features_for_triplets_groups, Data\n",
    "from itertools import chain\n",
    "import torch\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph...\n",
      "Encoding questions...\n",
      "Retrieving subgraphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 58.23it/s]00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subgraphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ds = UpdatedWebQSPDataset(\"small_ds\", force_reload=True, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = list(chain.from_iterable((d['graph'] for d in ds.raw_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is the name of justin bieber brother',\n",
       " 'what character did natalie portman play in star wars',\n",
       " 'what country is the grand bahama island in',\n",
       " 'what kind of money to take to bahamas',\n",
       " 'what character did john noble play in lord of the rings',\n",
       " 'who does joakim noah play for',\n",
       " 'where are the nfl redskins from',\n",
       " 'where did saki live',\n",
       " 'who did draco malloy end up marrying',\n",
       " 'which countries border the us']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = ds.raw_dataset['question']\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_graphs = get_features_for_triplets_groups(ds.indexer, (d['graph'] for d in ds.raw_dataset), pre_transform=preprocess_triplet)\n",
    "num_edges = len(ds.indexer._edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, gs = create_remote_backend_from_triplets(triplets=triplets, node_embedding_model=model, node_method_to_call=\"encode\", path=\"backend\", pre_transform=preprocess_triplet, node_method_kwargs={\"batch_size\": 256}, graph_db=NeighborSamplingRAGGraphStore, feature_db=SentenceTransformerFeatureStore).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loader = RAGQueryLoader(data=(fs, gs), seed_nodes_kwargs={\"k_nodes\": 10}, seed_edges_kwargs={\"k_edges\": 10}, sampler_kwargs={\"num_neighbors\": [40]*10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Metrics to be added to Profiler\n",
    "def _eidx_helper(subg: Data, ground_truth: Data):\n",
    "    subg_eidx, gt_eidx = subg.edge_idx, ground_truth.edge_idx\n",
    "    if isinstance(subg_eidx, torch.Tensor):\n",
    "        subg_eidx = subg_eidx.tolist()\n",
    "    if isinstance(gt_eidx, torch.Tensor):\n",
    "        gt_eidx = gt_eidx.tolist()\n",
    "    subg_e = set(subg_eidx)\n",
    "    gt_e = set(gt_eidx)\n",
    "    return subg_e, gt_e\n",
    "def check_retrieval_accuracy(subg: Data, ground_truth: Data, num_edges: int):\n",
    "    subg_e, gt_e = _eidx_helper(subg, ground_truth)\n",
    "    total_e = set(range(num_edges))\n",
    "    tp = len(subg_e & gt_e)\n",
    "    tn = len(total_e-(subg_e | gt_e))\n",
    "    return (tp+tn)/num_edges\n",
    "def check_retrieval_precision(subg: Data, ground_truth: Data):\n",
    "    subg_e, gt_e = _eidx_helper(subg, ground_truth)\n",
    "    return len(subg_e & gt_e) / len(subg_e)\n",
    "def check_retrieval_recall(subg: Data, ground_truth: Data):\n",
    "    subg_e, gt_e = _eidx_helper(subg, ground_truth)\n",
    "    return len(subg_e & gt_e) / len(gt_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  12,    9,   29,  ..., 4320, 4320,  203],\n",
       "        [   0,    1,    2,  ..., 4335, 4336, 4336]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_loader.query(questions[0]).edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 58.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5298204220736663 0.22839287819832568 0.4442151129457631\n",
      "0.5446847555380784 0.1108633135747403 0.4599464329194059\n",
      "0.5419845327041551 0.05783118608816223 0.4625693160813309\n",
      "0.5353781622755276 0.1497463408945128 0.4497373029772329\n",
      "0.5505046532966312 0.038434331525583586 0.4387617765814266\n",
      "0.5276445143531262 0.07287290651431132 0.4701843151427539\n",
      "0.5448420500720933 0.10575959441136591 0.44996237772761477\n",
      "0.5472276838379866 0.06082667919210897 0.4482907832107313\n",
      "0.5396775462052694 0.10320740438907969 0.4516046867040244\n",
      "0.5173417223751474 0.17134230030194894 0.4847778813296055\n"
     ]
    }
   ],
   "source": [
    "for subg, gt in zip((query_loader.query(q) for q in questions), ground_truth_graphs):\n",
    "    print(check_retrieval_accuracy(subg, gt, num_edges), check_retrieval_precision(subg, gt), check_retrieval_recall(subg, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_retrieval_via_pcst(graph: Data, query: str, topk: int = 3, topk_e: int = 3, cost_e: float = 0.5) -> Tuple[Data, str]:\n",
    "    q_emb = model.encode(query)\n",
    "    textual_nodes = ds.textual_nodes.iloc[graph[\"node_idx\"]].reset_index()\n",
    "    textual_edges = ds.textual_edges.iloc[graph[\"edge_idx\"]].reset_index()\n",
    "    out_graph, desc = retrieval_via_pcst(graph, q_emb, textual_nodes, textual_edges, topk, topk_e, cost_e)\n",
    "    out_graph[\"desc\"] = desc\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loader = RAGQueryLoader(data=(fs, gs), seed_nodes_kwargs={\"k_nodes\": 10}, seed_edges_kwargs={\"k_edges\": 10}, sampler_kwargs={\"num_neighbors\": [40]*10}, local_filter=apply_retrieval_via_pcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5534146021759078 0.0007042666823170373 0.6\n",
      "0.5555118626294403 0.00017691808692575338 0.75\n",
      "0.5525756979944947 0.0001757881167233095 0.42857142857142855\n",
      "0.5580547909293485 0.00011862396204033214 1.0\n",
      "0.5605977192292568 5.966587112171838e-05 0.3333333333333333\n",
      "0.5426923581072225 0.00017200848575196377 0.3333333333333333\n",
      "0.5530475815965396 0.00011729517330361856 1.0\n",
      "0.553126228863547 0.0002933239469670304 0.5\n",
      "0.5531000131078778 0.00029337557941676935 0.35714285714285715\n",
      "0.5271464149954123 5.545389009038984e-05 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "for subg, gt in zip((query_loader.query(q) for q in questions), ds):\n",
    "    print(check_retrieval_accuracy(subg, gt, num_edges), check_retrieval_precision(subg, gt), check_retrieval_recall(subg, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg-local-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
